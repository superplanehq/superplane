package claude

import (
	"fmt"
	"net/http"
	"strings"

	"github.com/google/uuid"
	"github.com/mitchellh/mapstructure"
	"github.com/superplanehq/superplane/pkg/configuration"
	"github.com/superplanehq/superplane/pkg/core"
)

const MessagePayloadType = "claude.message"

type TextPrompt struct{}

type TextPromptSpec struct {
	Model         string   `json:"model"`
	Prompt        string   `json:"prompt"`
	SystemMessage string   `json:"systemMessage"`
	MaxTokens     int      `json:"maxTokens"`
	Temperature   *float64 `json:"temperature"`
}

type MessagePayload struct {
	ID         string                 `json:"id"`
	Model      string                 `json:"model"`
	Text       string                 `json:"text"`
	Usage      *MessageUsage          `json:"usage,omitempty"`
	StopReason string                 `json:"stopReason,omitempty"`
	Response   *CreateMessageResponse `json:"response"`
}

func (c *TextPrompt) Name() string {
	return "claude.textPrompt"
}

func (c *TextPrompt) Label() string {
	return "Text Prompt"
}

func (c *TextPrompt) Description() string {
	return "Generate a response using Anthropic's Claude models via the Messages API"
}

func (c *TextPrompt) Documentation() string {
	return `The Text Prompt component uses Anthropic's Claude models to generate text responses.

## Use Cases

- **Summarization**: Generate summaries of incidents or deployments.
- **Code Analysis**: specific code review or PR comments.
- **Content Generation**: Create documentation or drafting communications.

## Configuration

- **Model**: The Claude model to use (e.g., claude-3-5-sonnet-latest).
- **Prompt**: The main user message/instruction.
- **System Message**: (Optional) Context to define the assistant's behavior or persona.
- **Max Tokens**: (Optional) Limit the length of the generated response.
- **Temperature**: (Optional) Control randomness (0.0 to 1.0).

## Output

Returns a payload containing:
- **text**: The content generated by Claude.
- **usage**: Input and output token counts.
- **stopReason**: Why the generation ended (e.g., "end_turn", "max_tokens").
- **model**: The specific model version used.

## Notes

- Requires a valid Claude API key configured in integration
- Response quality and speed depend on the selected model
- Token usage is tracked and may incur costs based on your Claude plan
`
}

func (c *TextPrompt) Icon() string {
	return "message-square"
}

func (c *TextPrompt) Color() string {
	return "orange"
}

func (c *TextPrompt) OutputChannels(configuration any) []core.OutputChannel {
	return []core.OutputChannel{core.DefaultOutputChannel}
}

func (c *TextPrompt) Configuration() []configuration.Field {
	return []configuration.Field{
		{
			Name:        "model",
			Label:       "Model",
			Type:        configuration.FieldTypeIntegrationResource,
			Required:    true,
			Default:     "claude-opus-4-6",
			Placeholder: "Select a Claude model",
			TypeOptions: &configuration.TypeOptions{
				Resource: &configuration.ResourceTypeOptions{
					Type: "model",
				},
			},
		},
		{
			Name:        "prompt",
			Label:       "Prompt",
			Type:        configuration.FieldTypeText,
			Required:    true,
			Placeholder: "Enter the user prompt",
			Description: "The main instruction or question for Claude",
		},
		{
			Name:        "systemMessage",
			Label:       "System Message",
			Type:        configuration.FieldTypeText,
			Required:    false,
			Placeholder: "e.g. You are a concise DevOps assistant",
			Description: "Optional context to set behavior or persona",
		},
		{
			Name:        "maxTokens",
			Label:       "Max Tokens",
			Type:        configuration.FieldTypeNumber,
			Required:    false,
			Default:     "4096",
			Description: "Maximum number of tokens to generate e.g. Defaults to 4096.",
		},
		{
			Name:        "temperature",
			Label:       "Temperature",
			Type:        configuration.FieldTypeNumber,
			Required:    false,
			Default:     "1.0",
			Description: "Amount of randomness injected into the response (0.0 to 1.0)",
		},
	}
}

func (c *TextPrompt) Setup(ctx core.SetupContext) error {
	spec := TextPromptSpec{}
	if err := mapstructure.Decode(ctx.Configuration, &spec); err != nil {
		return fmt.Errorf("failed to decode configuration: %v", err)
	}

	if spec.Model == "" {
		return fmt.Errorf("model is required")
	}

	if spec.Prompt == "" {
		return fmt.Errorf("prompt is required")
	}

	return nil
}

func (c *TextPrompt) Execute(ctx core.ExecutionContext) error {
	spec := TextPromptSpec{}
	if err := mapstructure.Decode(ctx.Configuration, &spec); err != nil {
		return fmt.Errorf("failed to decode configuration: %v", err)
	}

	if spec.Model == "" {
		return fmt.Errorf("model is required")
	}
	if spec.Prompt == "" {
		return fmt.Errorf("prompt is required")
	}

	if spec.MaxTokens == 0 {
		spec.MaxTokens = 4096
	}

	if spec.MaxTokens < 1 {
		return fmt.Errorf("maxTokens must be at least 1")
	}

	client, err := NewClient(ctx.HTTP, ctx.Integration)
	if err != nil {
		return err
	}

	req := CreateMessageRequest{
		Model:     spec.Model,
		MaxTokens: spec.MaxTokens,
		Messages: []Message{
			{
				Role:    "user",
				Content: spec.Prompt,
			},
		},
		Temperature: spec.Temperature,
	}

	if spec.SystemMessage != "" {
		req.System = spec.SystemMessage
	}

	response, err := client.CreateMessage(req)
	if err != nil {
		return err
	}

	text := extractMessageText(response)

	payload := MessagePayload{
		ID:         response.ID,
		Model:      response.Model,
		Text:       text,
		Usage:      &response.Usage,
		StopReason: response.StopReason,
		Response:   response,
	}

	return ctx.ExecutionState.Emit(
		core.DefaultOutputChannel.Name,
		MessagePayloadType,
		[]any{payload},
	)
}

func (c *TextPrompt) Cancel(ctx core.ExecutionContext) error {
	return nil
}

func (c *TextPrompt) ProcessQueueItem(ctx core.ProcessQueueContext) (*uuid.UUID, error) {
	return ctx.DefaultProcessing()
}

func (c *TextPrompt) Actions() []core.Action {
	return []core.Action{}
}

func (c *TextPrompt) HandleAction(ctx core.ActionContext) error {
	return nil
}

func (c *TextPrompt) HandleWebhook(ctx core.WebhookRequestContext) (int, error) {
	return http.StatusOK, nil
}

func (c *TextPrompt) Cleanup(ctx core.SetupContext) error {
	return nil
}

func extractMessageText(response *CreateMessageResponse) string {
	if response == nil || len(response.Content) == 0 {
		return ""
	}

	var builder strings.Builder
	for _, block := range response.Content {
		if block.Type == "text" {
			if builder.Len() > 0 {
				builder.WriteString("\n")
			}
			builder.WriteString(block.Text)
		}
	}
	return builder.String()
}
